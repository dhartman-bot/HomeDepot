# Claude Code Sales Qualification Framework
## Based on "The Qualified Sales Leader" Methodology

---

## Executive Summary

This framework provides Anthropic sales representatives with a structured approach to qualify prospects, design effective POCs, and accelerate Claude Code adoption. Built on proven B2B sales methodologies, it ensures we're engaging the right stakeholders, solving real problems, and creating measurable business value.

---

## Part 1: MEDDPICC Qualification Framework for Claude Code

### **M - Metrics (Quantifiable Business Impact)**

**Key Questions:**
- What does developer productivity cost you today per developer per year?
- How many developers would use Claude Code? (Target: 50-500+ for enterprise)
- What's your current cost of code review, bug fixes, and technical debt?
- What's the business impact of faster feature delivery? (Revenue per week of acceleration)
- What's your developer turnover rate and cost to replace? (Retention impact)

**Success Metrics to Track:**
- **Developer Velocity**: 30-50% reduction in time-to-completion for coding tasks
- **Code Quality**: 20-40% reduction in bugs/regressions in production
- **Developer Satisfaction**: +20-30 point NPS improvement
- **ROI Timeline**: Positive ROI within 3-6 months at scale
- **Time Savings**: 5-10 hours per developer per week recovered

**Qualification Threshold:**
- Minimum 50 developers for enterprise deals
- Clear ability to measure at least 2 of the 5 success metrics above
- Executive sponsor who owns developer productivity budget ($5M+ annually)

---

### **E - Economic Buyer (Who Controls the Budget)**

**Primary Economic Buyers:**
- **CTO/VP Engineering**: Owns developer productivity, tooling budget
- **Head of Developer Experience/Platform Engineering**: Direct budget owner
- **CIO**: For enterprise-wide developer tool standardization
- **CFO/COO**: For large-scale digital transformation initiatives

**Key Questions:**
- Who owns the developer tooling budget? What's the annual allocation?
- Who has authority to approve a $500K+ software investment?
- Is there budget allocated this year/quarter for developer productivity?
- What's the approval process? (Single signature vs. committee)
- Have they purchased similar tools before? (GitHub Copilot, Cursor, etc.)

**Red Flags:**
- Economic buyer not identified by discovery call 2
- "We need to build a business case" without executive sponsor
- Budget owner not engaged in POC design
- No clear budget or "we'll find budget if it works"

---

### **D - Decision Criteria (How They'll Choose)**

**Technical Criteria:**
- IDE integration requirements (VS Code, JetBrains, etc.)
- Security & compliance requirements (SOC2, HIPAA, GDPR)
- Model performance on their specific tech stack
- Context window needs (codebase size)
- Deployment model (Cloud, AWS Bedrock, etc.)

**Business Criteria:**
- ROI payback period (typically 6-12 months acceptable)
- Total Cost of Ownership vs. alternatives
- Vendor stability and support SLAs
- Integration with existing dev tools (GitHub, GitLab, Jira)
- Change management and adoption support

**Key Questions:**
- What criteria will you use to evaluate Claude Code vs. alternatives?
- How will you measure success? What's the threshold to move forward?
- Who needs to approve each criterion? (Technical vs. business)
- What happens if we meet all criteria? What's the next step?
- What would cause you to choose a competitor or status quo?

**Our Differentiation:**
- **Best-in-class coding performance**: 73.3%+ on SWE-bench Verified
- **Enterprise security**: SOC2, HIPAA compliant, data not used for training
- **Flexible deployment**: AWS Bedrock, API, or managed cloud
- **Extended context**: 1M token context window for large codebases
- **Autonomous agents**: Multi-step task automation with Claude Code

---

### **D - Decision Process (How They'll Buy)**

**Typical B2B Software Decision Process:**
1. **Initial Discovery** (Week 1-2): Identify pain, stakeholders, budget
2. **Technical Evaluation** (Week 3-4): POC with 10-20 pilot developers
3. **Business Case Review** (Week 5-6): ROI analysis with finance/exec team
4. **Security/Legal Review** (Week 6-8): InfoSec, legal, procurement
5. **Pilot Expansion** (Week 9-12): 50-100 users, refine use cases
6. **Contract Negotiation** (Week 13-16): Pricing, terms, MSA
7. **Full Rollout** (Month 5-6): Organization-wide deployment

**Key Questions:**
- Walk me through how you've purchased similar tools (GitHub, Jira, etc.)
- Who needs to be involved at each stage?
- What's your typical procurement timeline for $500K+ software?
- Are there any upcoming budget cycles or freeze periods?
- What could slow down or derail this process?

**Acceleration Tactics:**
- Get economic buyer involved by Call 2
- Align POC to active project with hard deadline
- Pre-clear security/legal requirements before POC
- Build champion in engineering who will advocate internally
- Create urgency with business impact (revenue delay, competitive threat)

---

### **P - Paper Process (Procurement & Legal)**

**Common Procurement Requirements:**
- Security questionnaire (SOC2, pentest reports)
- Data Processing Agreement (DPA)
- Master Services Agreement (MSA) review
- Vendor risk assessment
- Privacy impact assessment (GDPR, CCPA)
- Export control compliance (ITAR, EAR)

**Key Questions:**
- What's your standard vendor onboarding process?
- How long does legal review typically take?
- Do you have a preferred MSA or will you use ours?
- Are there any non-standard terms we should know about?
- Who manages vendor risk assessment? Can we start now?

**Acceleration Tactics:**
- Get procurement involved during POC (not after)
- Provide security documentation upfront
- Use AWS Bedrock deployment to simplify compliance
- Leverage existing AWS BAA/DPA if they're AWS customers
- Offer standard MSA with minimal negotiation

---

### **I - Identify Pain (Critical Business Problem)**

**Top Claude Code Pain Points:**

1. **Slow Feature Delivery**
   - "We can't ship fast enough to hit revenue targets"
   - "Competitors are out-innovating us"
   - "Engineering is a bottleneck to growth"

2. **Developer Shortage/Retention**
   - "We can't hire fast enough - need to 10x productivity"
   - "Junior developers take 6 months to ramp"
   - "Top developers are leaving due to tedious work"

3. **Technical Debt & Code Quality**
   - "We spend 50% of time on bug fixes, not features"
   - "Code reviews are a bottleneck (2-3 days)"
   - "Legacy code is impossible to maintain"

4. **High Cost of Development**
   - "Our cost per feature is 3x industry average"
   - "Offshore teams aren't delivering the quality we need"
   - "We're spending $10M/year on dev resources"

**Qualification Questions:**
- What's the business impact of this problem? (Revenue loss, cost, risk)
- How long have you had this problem?
- What have you tried to solve it? Why didn't it work?
- What happens if you don't solve it in the next 6-12 months?
- Is this a top 3 priority for your exec team?

**Red Flags:**
- Pain is "nice to have" not "must solve"
- No clear business impact or urgency
- Problem is not tied to executive objectives
- Multiple competing priorities

---

### **C - Champion (Internal Advocate)**

**Ideal Champion Profile:**
- **Title**: Senior/Staff Engineer, Engineering Manager, or Architect
- **Influence**: Respected technical leader, 5+ years at company
- **Motivation**: Personally feels pain, wants to solve it
- **Access**: Can get us meetings with VP Eng, CTO
- **Risk-taker**: Willing to advocate for new tools

**Key Questions:**
- Who will own the success of this evaluation internally?
- Who has successfully championed new tools here before?
- Can you help us get 30 minutes with [Economic Buyer]?
- Will you present the POC results to your leadership team?
- What do you need from us to make you successful?

**Champion Development:**
- Give them early access to Claude Code
- Make them look like a hero (provide ROI data, exec slides)
- Regular check-ins (weekly during POC)
- Equip them with talking points for internal advocacy
- Celebrate their wins publicly

**Red Flags:**
- No clear champion by end of discovery
- Champion has no influence or is too junior
- Champion is not engaged or responsive
- Champion can't get us access to economic buyer

---

### **C - Competition (What Else Are They Considering)**

**Direct Competitors:**
- **GitHub Copilot**: Incumbent, widely deployed, lower performance
- **Cursor**: Strong IDE integration, lacks enterprise features
- **Codeium**: Low cost, less sophisticated
- **Amazon Q Developer**: AWS native, less capable

**Indirect Competition:**
- **Status Quo**: Developers without AI assistance
- **Build In-House**: Custom LLM + RAG solution
- **Offshore Teams**: Labor arbitrage instead of AI

**Key Questions:**
- What other solutions are you evaluating?
- What do you like/dislike about [Competitor]?
- Do you have GitHub Copilot deployed today? What's the experience?
- Why are you looking for alternatives?
- If you do nothing, what happens?

**Our Competitive Positioning:**

| **Criteria** | **Claude Code** | **GitHub Copilot** | **Cursor** |
|--------------|-----------------|-------------------|------------|
| **SWE-bench Performance** | 73.3% (Haiku 4.5) | ~40-50% | ~60% |
| **Context Window** | 1M tokens | 128K tokens | 200K tokens |
| **Enterprise Security** | ✓ SOC2, HIPAA | ✓ SOC2 | Limited |
| **Deployment Options** | Cloud, AWS Bedrock | Cloud only | Cloud only |
| **Autonomous Agents** | ✓ Multi-step tasks | X Single completions | X Single completions |
| **Data Privacy** | Not used for training | Opt-out required | Not used for training |

**How to Handle Competition:**
- Don't bad-mouth competitors (unprofessional)
- Focus on our differentiation: performance, security, flexibility
- Use proof points: SWE-bench scores, customer case studies
- Offer side-by-side POC on same use cases
- Position as "evolution" not "replacement" if they have Copilot

---

## Part 2: POC Use Cases & Success Criteria

### **POC Design Principles (McMahon Method)**

1. **Align to Real Business Pain**: POC must solve actual problem, not sandbox
2. **Measurable Success Criteria**: Define metrics upfront (before POC starts)
3. **Right Stakeholders**: Economic buyer and champion both engaged
4. **Realistic Timeline**: 2-4 weeks max (urgency drives adoption)
5. **Clear Go/No-Go Decision**: "If we hit X metric, we move to contract"

---

### **Tier 1 POC Use Cases (High Impact, Fast Wins)**

#### **Use Case 1: Feature Development Acceleration**

**Scenario**: Development team building new customer-facing feature with hard deadline

**Success Criteria:**
- 40% reduction in development time vs. historical baseline
- Feature delivered on time (vs. projected 2-week delay)
- Code passes all tests and code review on first submission
- Developer satisfaction score 8+ / 10

**POC Setup:**
- Select 5-10 developers on active feature project
- Baseline: Time to complete similar features historically
- Duration: 2-3 week sprint
- Measurement: Track hours, commits, story points completed

**Expected ROI:**
- Typical feature: 3 developers × 2 weeks = 240 hours → Save 96 hours
- Value at $100/hour loaded cost = $9,600 per feature
- Annualized: 20 features/year × $9,600 = $192K savings for small team

---

#### **Use Case 2: Bug Fix & Debugging Speed**

**Scenario**: Engineering team spends 50%+ time on bug fixes, incident response

**Success Criteria:**
- 50% reduction in time to identify root cause
- 30% reduction in time to implement fix
- 20% reduction in regression bugs introduced
- Faster MTTR (Mean Time To Repair) for production incidents

**POC Setup:**
- Select 5 engineers on-call rotation or maintenance team
- Track all bugs/incidents for 2 weeks
- Compare time-to-resolution vs. previous 4-week baseline
- Measure code quality of fixes (regression rate)

**Expected ROI:**
- Typical team: 5 engineers × 20 hours/week on bugs = 100 hours/week
- 30% time savings = 30 hours/week = $3,000/week savings
- Annualized: $156K savings for small team

---

#### **Use Case 3: Code Review & Technical Debt Reduction**

**Scenario**: Code reviews take 2-3 days, blocking feature delivery

**Success Criteria:**
- 50% reduction in code review time (reviewer side)
- 40% fewer review cycles (code is cleaner on first submission)
- Increased consistency in code style/patterns
- Developer satisfaction with review process improves by 20+ points

**POC Setup:**
- 10 developers on team with active PR workflow
- Use Claude Code for pre-review cleanup and documentation
- Track PR open time, number of review cycles, comments
- Survey developers on review experience (before/after)

**Expected ROI:**
- Typical PR: 4 hours reviewer time → Reduced to 2 hours = 2 hours saved
- Team of 10 devs: 20 PRs/week × 2 hours = 40 hours/week = $4,000/week
- Annualized: $208K savings

---

#### **Use Case 4: Legacy Code Modernization**

**Scenario**: Critical legacy system needs migration (Java → Spring Boot, .NET → .NET Core, etc.)

**Success Criteria:**
- 60% reduction in migration time vs. manual approach
- Zero regressions or functional changes (test coverage maintained)
- Documentation auto-generated for new code
- Team can maintain new codebase with 50% less effort

**POC Setup:**
- Select one module/service to migrate (not full system)
- Baseline: Estimate manual migration time from prior experience
- Duration: 3-4 weeks
- Measure: Actual time, test coverage, bugs found

**Expected ROI:**
- Typical migration: 2,000 hours estimated → 800 hours saved = $80K
- Full system: 10 modules × $80K = $800K total savings
- Plus ongoing maintenance savings (50% reduction)

---

#### **Use Case 5: Test Automation & Coverage**

**Scenario**: Test coverage is low (<60%), QA is manual and slow

**Success Criteria:**
- Increase unit test coverage from 60% → 80%+ in POC period
- 50% reduction in time to write tests
- Tests catch 30% more bugs before production
- Developers write tests proactively (cultural shift)

**POC Setup:**
- Select 5 developers on team with low test coverage
- Use Claude Code to auto-generate tests for existing code
- Track coverage %, time to write tests, bugs caught
- Duration: 2-3 weeks

**Expected ROI:**
- Reduce production bugs by 30%: Typical cost of bug = $5K avg (customer impact, eng time)
- Team ships 20 bugs/year → Save 6 bugs = $30K/year
- Plus time savings: 50% reduction in test writing time = 5 hours/week/dev = $26K/year

---

### **Tier 2 POC Use Cases (Strategic, Longer-Term)**

#### **Use Case 6: Onboarding & Developer Ramp Time**

**Success Criteria:**
- New hire productivity reaches 80% by week 4 (vs. week 12 baseline)
- 50% reduction in "where is this code?" questions
- New developers ship first meaningful PR by end of week 2

**POC Setup:**
- Run with 3-5 new hires during POC period
- Track time to first PR, questions asked, manager assessment
- Compare to historical onboarding cohorts

---

#### **Use Case 7: API & Documentation Generation**

**Success Criteria:**
- Auto-generate API documentation for 100% of endpoints
- Reduce time to write documentation by 70%
- Developer satisfaction with docs improves by 30+ points

**POC Setup:**
- Select team with poor documentation
- Use Claude Code to generate docs for existing APIs
- Track time savings, doc quality (survey internal users)

---

#### **Use Case 8: Security Vulnerability Remediation**

**Success Criteria:**
- Reduce time to fix security vulnerabilities by 50%
- Increase % of vulnerabilities fixed within SLA (7 days) from 60% → 90%
- Reduce false positive security alerts by 30%

**POC Setup:**
- Use on team managing security backlog
- Track time to triage, fix, and validate security issues
- Measure remediation rates before/after

---

## Part 3: POC Execution Playbook

### **Phase 1: Pre-POC Setup (Week 0)**

**Goals:**
- Get exec sponsorship and clear success criteria
- Select right use case and team
- Set expectations and timeline

**Key Activities:**
1. **Executive Alignment Call** (Economic Buyer + Champion)
   - Present POC plan and success metrics
   - Get commitment: "If we hit these metrics, what happens next?"
   - Confirm budget, timeline, and decision-makers

2. **Technical Kickoff** (Champion + Pilot Team)
   - Install Claude Code for 10-20 pilot users
   - Select specific project/use case
   - Baseline current performance (time, quality, satisfaction)

3. **Weekly Check-in Schedule**
   - Set up weekly calls with champion (Mon/Fri)
   - Monthly business review with economic buyer
   - Slack channel for real-time support

**Deliverables:**
- POC Charter document (signed by exec sponsor)
- Baseline metrics documented
- Pilot user list and use case defined

---

### **Phase 2: POC Execution (Week 1-4)**

**Goals:**
- Pilot users actively using Claude Code on real work
- Collect quantitative and qualitative feedback
- Build momentum and champions

**Key Activities:**

**Week 1: Onboarding & Training**
- 1-hour live training for pilot users
- Share best practices guide and use case examples
- First task: Have each user complete one task with Claude Code
- Daily check-ins first 3 days (fix blockers fast)

**Week 2-3: Active Usage & Data Collection**
- Users working on POC use case full-time
- Track metrics daily (time savings, completions, satisfaction)
- Mid-POC check-in with champion (course-correct if needed)
- Share early wins with exec sponsor (email updates)

**Week 4: Results Analysis & Business Case**
- Compile data: time savings, quality metrics, user feedback
- Build ROI model: Cost savings × scale = business case
- Create executive presentation (10 slides max)
- Schedule POC readout with economic buyer

**Deliverables:**
- Weekly progress reports to champion
- ROI calculator showing projected savings at scale
- Executive summary (1-pager) of POC results
- User testimonials and quotes

---

### **Phase 3: POC Readout & Decision (Week 5)**

**Goals:**
- Present compelling business case to decision-makers
- Get clear go/no-go decision
- Agree on next steps (pilot expansion or full contract)

**Executive Readout Structure (30-minute meeting):**

**Slides 1-2: Business Context** (3 minutes)
- Remind them of original pain point and goals
- Success criteria agreed upon at POC start

**Slides 3-5: POC Results** (10 minutes)
- Quantitative metrics (time savings, quality improvements)
- Qualitative feedback (user quotes, satisfaction scores)
- Comparison to success criteria (did we hit targets?)

**Slides 6-7: Scaled Business Case** (5 minutes)
- ROI model: Savings per developer × total developers
- Payback period (typically 3-6 months)
- 3-year NPV and cost savings projection

**Slides 8-9: Risks & Mitigation** (5 minutes)
- Adoption challenges and change management plan
- Security/compliance (already cleared in POC)
- Support and training plan

**Slide 10: Recommendation & Next Steps** (7 minutes)
- Clear ask: "We recommend moving forward with 100-user pilot"
- Timeline to full deployment (3-6 months)
- Decision needed today: Yes/No/What's missing?

**Keys to Success:**
- Let champion present (they're the hero)
- Use customer's own data (not generic case studies)
- Tie to exec's goals (revenue growth, cost reduction, talent retention)
- Make it easy to say yes (pre-cleared legal, standard pricing)

---

### **Phase 4: Objection Handling & Close**

**Common Objections:**

**"We need to evaluate other vendors"**
- *Response*: "That's reasonable. Can we do a side-by-side POC on the same use case? We're confident Claude Code will outperform on [key criteria]."

**"Budget is tight this quarter"**
- *Response*: "I understand. Based on our POC, you're losing $X per week by not having this tool. The payback is under 4 months. Can we start with 50 users this quarter and expand next quarter?"

**"We're worried about adoption"**
- *Response*: "Great point. In the POC, we saw 90% of users actively using Claude Code by week 2. We'll provide onboarding, best practices, and a dedicated CSM to ensure success."

**"We already have GitHub Copilot"**
- *Response*: "Many of our customers started with Copilot and upgraded to Claude Code for [better performance / enterprise security / autonomous agents]. Would you be open to a 2-week side-by-side test?"

**"We want to build our own solution"**
- *Response*: "We've seen companies try this. It typically takes 18-24 months and $2M+ in engineering cost. Claude Code delivers results in 30 days. Can we show you the time-to-value difference?"

---

## Part 4: Qualification Scorecard

Use this scorecard after Discovery Call 1 and 2 to determine if opportunity is qualified.

| **Criteria** | **Weight** | **Score (1-5)** | **Weighted Score** |
|--------------|------------|-----------------|-------------------|
| **Pain Severity**: Critical business problem (revenue, cost, risk) | 20% | ___ | ___ |
| **Economic Buyer**: Identified and engaged by Call 2 | 20% | ___ | ___ |
| **Budget**: $500K+ allocated or accessible this year | 15% | ___ | ___ |
| **Champion**: Strong internal advocate with influence | 15% | ___ | ___ |
| **Decision Criteria**: Clear, measurable, we can win | 10% | ___ | ___ |
| **Timeline**: Decision in next 90 days | 10% | ___ | ___ |
| **Competition**: We're preferred or can differentiate | 5% | ___ | ___ |
| **Scale**: 50+ developers (enterprise) | 5% | ___ | ___ |

**Total Weighted Score: ______ / 5.0**

**Qualification Thresholds:**
- **4.0+**: Highly qualified - Invest heavily, fast-track POC
- **3.0-3.9**: Qualified - Standard POC process
- **2.0-2.9**: Marginal - Nurture, don't commit POC resources yet
- **<2.0**: Not qualified - Politely disengage or nurture long-term

---

## Part 5: Sales Process Timeline

**Typical Timeline: 90-120 Days from First Call to Contract**

### **Month 1: Discovery & Qualification**
- **Week 1-2**: Initial discovery calls, identify stakeholders
- **Week 3-4**: Executive alignment, POC planning

### **Month 2: POC Execution**
- **Week 5-7**: Pilot users actively using Claude Code
- **Week 8**: POC results analysis and business case

### **Month 3: Decision & Contracting**
- **Week 9-10**: Executive readout and decision
- **Week 11-12**: Legal/procurement, contract negotiation

### **Month 4: Pilot Expansion (Optional)**
- **Week 13-16**: Expand to 100-200 users, validate at scale

### **Month 5-6: Full Deployment**
- Roll out to entire organization

**Acceleration Tactics:**
- Collapse discovery + POC into 4 weeks (vs. 8) with urgent business case
- Use AWS Bedrock to skip security review
- Get verbal commitment from exec before POC ("if results are X, we'll move forward")
- Pre-negotiate pricing and terms during POC

---

## Part 6: Key Qualification Questions (Discovery Calls)

### **Discovery Call 1: Understand the Problem (30-45 min)**

**Business Context:**
1. Tell me about your engineering organization (size, structure, tech stack)
2. What are your top 3 priorities this year? Where does engineering fit?
3. What's preventing you from hitting those goals today?

**Pain Identification:**
4. How long does it take to ship a typical feature? Too slow, too fast, or about right?
5. What % of engineering time is spent on new features vs. maintenance/bugs?
6. How's your developer retention? Are you able to hire the talent you need?
7. If you could wave a magic wand and 10x developer productivity, what would that unlock?

**Current State:**
8. What tools do developers use today? (IDEs, AI assistants, code review tools)
9. If you have GitHub Copilot or similar, what's working and what's not?
10. What have you tried to solve this problem? Why didn't it work?

**Stakeholders:**
11. Who else should I be talking to about this?
12. Who owns the budget for developer tools and productivity?

---

### **Discovery Call 2: Qualify & Design POC (45-60 min)**

**Economic Buyer & Budget:**
1. Can we get 30 minutes with [CTO/VP Eng] to align on this?
2. What's your annual budget for developer tooling?
3. Is there budget allocated this year/quarter, or do we need to build a business case?

**Decision Criteria:**
4. If we run a POC, what would success look like? How will you measure it?
5. What criteria will you use to choose between Claude Code and alternatives?
6. Who needs to approve this decision? What's the process?

**Competition:**
7. What other solutions are you evaluating?
8. If you do nothing, what happens? (Status quo cost)

**POC Design:**
9. What's a real project/team we could pilot this with?
10. Can we start next week? What would prevent us from moving fast?

**Close:**
11. If the POC hits your success criteria, what happens next?
12. Are there any reasons we wouldn't move forward if we deliver results?

---

## Part 7: Success Playbook - First 90 Days

### **Rep Priorities**

**Days 1-30: Build Pipeline**
- Goal: 20 qualified opportunities in pipeline
- Activities: Outbound, demo webinars, conference follow-up
- Metrics: 50 discovery calls → 20 qualified opps (40% conversion)

**Days 31-60: Run POCs**
- Goal: 10 active POCs running simultaneously
- Activities: POC kickoffs, weekly champion check-ins
- Metrics: 80% of POCs hit success criteria

**Days 61-90: Close Deals**
- Goal: 5 contracts signed, $2M+ in ARR
- Activities: Executive readouts, contract negotiation
- Metrics: 50% close rate on successful POCs

### **Manager Coaching Focus**

**Weekly 1:1s - Inspect Deals Using MEDDPICC:**
- "Walk me through the economic buyer - have you met them?"
- "What are the quantified metrics they care about?"
- "Who's the competition and why are we better?"
- "What's the decision process and timeline?"

**Monthly Business Reviews:**
- Pipeline health: Qualified vs. unqualified opportunities
- POC success rate and common failure points
- Win/loss analysis: Why are we winning/losing?

---

## Part 8: Resources for Reps

### **Sales Assets**

**Discovery:**
- ROI Calculator (customizable for each prospect)
- Pain point assessment questionnaire
- Executive sponsor email templates

**POC:**
- POC Charter template (1-pager)
- Best practices guide for pilot users
- Weekly progress report template

**Close:**
- Executive readout deck template (10 slides)
- Customer case studies and testimonials
- Security documentation (SOC2, pentest reports)

**Objection Handling:**
- Competitive battle cards (vs. Copilot, Cursor, etc.)
- Pricing and packaging FAQ
- Common objections and responses

### **Recommended Training**

**Week 1: Product & Market**
- Claude Code product deep-dive (2 hours)
- Demo certification
- Competitive positioning

**Week 2: Sales Methodology**
- MEDDPICC framework training
- POC design workshop
- Objection handling role-play

**Week 3: Customer Immersion**
- Ride-along with experienced rep
- Customer POC shadowing
- Listen to 5 discovery call recordings

**Week 4: Certification**
- Mock discovery call (pass/fail)
- Mock POC readout (pass/fail)
- Shadow-to-lead transition

---

## Appendix A: Quick Reference Cheat Sheet

### **Minimum Qualification Criteria (Must Have All):**
- [ ] 50+ developers (enterprise segment)
- [ ] Economic buyer identified and engaged
- [ ] Budget exists or is accessible this year
- [ ] Clear, urgent business pain (top 3 priority)
- [ ] Champion willing to advocate internally
- [ ] Decision timeline within 90 days
- [ ] Can measure success quantitatively

### **Red Flags (Disqualify or Nurture):**
- No clear economic buyer or budget
- Pain is "nice to have" not urgent
- Champion has no influence or won't engage
- Timeline is >6 months or "just exploring"
- Company has <25 developers
- Security/compliance will take >90 days

### **POC Must-Haves:**
- Real project (not sandbox), active development
- 10-20 pilot users committed for 2-4 weeks
- Clear success metrics defined upfront
- Weekly check-ins with champion scheduled
- Executive sponsor agrees to readout at end

### **Success Criteria Examples:**
- 40% reduction in time to complete coding tasks
- 30% reduction in code review time
- 20+ point improvement in developer satisfaction (NPS)
- Zero security regressions or incidents
- 90% of pilot users actively using by week 2

---

## Appendix B: ROI Model Template

**Input Variables:**
- Number of developers: _____
- Average fully-loaded cost per developer: $150K/year ($75/hour)
- Hours saved per developer per week: 8 hours (conservative)
- Annual work weeks: 48 weeks (after holidays/vacation)

**Calculation:**
- **Annual time savings per developer**: 8 hours/week × 48 weeks = 384 hours/year
- **Annual cost savings per developer**: 384 hours × $75/hour = $28,800/year
- **Total annual savings**: [# developers] × $28,800

**Example: 200 Developer Organization**
- Total annual savings: 200 × $28,800 = **$5,760,000/year**
- Claude Code cost (estimated): 200 × $500/month × 12 = **$1,200,000/year**
- **Net savings Year 1**: $4,560,000
- **ROI**: 380% (3.8x return)
- **Payback period**: 2.5 months

**Additional Benefits (Not Quantified):**
- Faster time-to-market → Revenue acceleration
- Improved developer retention → Reduced hiring costs ($100K per replacement)
- Higher code quality → Fewer production incidents
- Better developer experience → Improved company reputation

---

## Conclusion

This qualification framework gives Anthropic sales representatives a proven methodology to:

1. **Qualify effectively** using MEDDPICC to focus on high-potential deals
2. **Design winning POCs** that deliver measurable business value
3. **Accelerate sales cycles** from 6+ months to 90 days
4. **Build compelling business cases** that get executive buy-in
5. **Handle objections** confidently with data and proof points

The key to success: **Qualify hard, close fast.** Focus on prospects with urgent business pain, clear budget, and executive sponsorship. Run POCs that solve real problems and deliver measurable ROI. Make it easy for customers to say "yes."

Remember McMahon's core principle: **"Qualify early, qualify often, and have the courage to walk away from bad deals."** Your time is your most valuable asset - invest it in deals you can win.

---

**Questions or feedback?** Contact: Dan Hartman (dhartman@anthropic.com)
